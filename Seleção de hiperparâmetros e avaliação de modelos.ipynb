{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-05 \t lamb:  0.001\n",
      "alpha:  0.0001 \t lamb:  0.001\n",
      "alpha:  0.001 \t lamb:  0.001\n",
      "alpha:  0.01 \t lamb:  0.001\n",
      "alpha:  0.1 \t lamb:  0.001\n",
      "alpha:  1e-05 \t lamb:  0.01778279410038923\n",
      "alpha:  0.0001 \t lamb:  0.01778279410038923\n",
      "alpha:  0.001 \t lamb:  0.01778279410038923\n",
      "alpha:  0.01 \t lamb:  0.01778279410038923\n",
      "alpha:  0.1 \t lamb:  0.01778279410038923\n",
      "alpha:  1e-05 \t lamb:  0.31622776601683794\n",
      "alpha:  0.0001 \t lamb:  0.31622776601683794\n",
      "alpha:  0.001 \t lamb:  0.31622776601683794\n",
      "alpha:  0.01 \t lamb:  0.31622776601683794\n",
      "alpha:  0.1 \t lamb:  0.31622776601683794\n",
      "alpha:  1e-05 \t lamb:  5.623413251903491\n",
      "alpha:  0.0001 \t lamb:  5.623413251903491\n",
      "alpha:  0.001 \t lamb:  5.623413251903491\n",
      "alpha:  0.01 \t lamb:  5.623413251903491\n",
      "alpha:  0.1 \t lamb:  5.623413251903491\n",
      "alpha:  1e-05 \t lamb:  100.0\n",
      "alpha:  0.0001 \t lamb:  100.0\n",
      "alpha:  0.001 \t lamb:  100.0\n",
      "alpha:  0.01 \t lamb:  100.0\n",
      "alpha:  0.1 \t lamb:  100.0\n"
     ]
    }
   ],
   "source": [
    "grid_search = np.meshgrid(np.logspace(-5, -1, 5), # alpha\n",
    "                          np.logspace(-3, 2, 5))  # lambda\n",
    "for i in range(grid_search[0].shape[0]):\n",
    "    for j in range(grid_search[1].shape[1]):\n",
    "        alpha = grid_search[0][i,j]\n",
    "        lamb = grid_search[1][i,j]\n",
    "        print(\"alpha: \",alpha ,\"\\t\",\"lamb: \" ,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationSplit(dataset, n_folds): \n",
    "    dataset_split = list() \n",
    "    dataset_copy = list(dataset) \n",
    "    fold_size = int(len(dataset) / n_folds) \n",
    "    \n",
    "    for i in range(n_folds): \n",
    "        fold = list() \n",
    "        while len(fold) < fold_size: \n",
    "            index = randrange(len(dataset_copy)) \n",
    "            fold.append(dataset_copy.pop(index)) \n",
    "        dataset_split.append(fold) \n",
    "    return dataset_split\n",
    "\n",
    "def kFoldCrossValidation(training, kParts, algorithm, *args):\n",
    "    folds = crossValidationSplit(dataset, kParts) \n",
    "    scores = list() \n",
    "    for fold in folds: \n",
    "        train_set = list(folds) \n",
    "        train_set.remove(fold) \n",
    "        train_set = sum(train_set, []) \n",
    "        test_set = list() \n",
    "        \n",
    "        for row in fold: \n",
    "            row_copy = list(row) \n",
    "            test_set.append(row_copy) \n",
    "            row_copy[-1] = None \n",
    "            \n",
    "        predicted = algorithm(train_set, test_set, *args) \n",
    "        actual = [row[-1] for row in fold] \n",
    "        accuracy = (predicted - actual)/kParts\n",
    "        scores.append(accuracy) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
