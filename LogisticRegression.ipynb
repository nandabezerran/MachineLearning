{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.read_csv('iris.csv', names =['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'flower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  flower\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xMatrix = np.array(data_table[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "yVector = np.array(data_table['flower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(matrix, vector):\n",
    "    #Mean calculation\n",
    "    mVector = np.mean(vector, axis=0)\n",
    "    mMatrix = np.mean(matrix, axis=0)\n",
    "    \n",
    "    #Standard deviation\n",
    "    stdVector = np.std(vector, axis = 0)\n",
    "    stdMatrix = np.std(matrix, axis = 0)\n",
    "     \n",
    "    #Normalization of data\n",
    "    vector = (vector - mVector)/stdVector\n",
    "    matrix = (matrix - mMatrix)/stdMatrix\n",
    "    \n",
    "    return matrix, vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(xMatrix, yVector, epochs, alpha):\n",
    "    xMatrix = np.insert(xMatrix, 0, 1, axis =1)\n",
    "    wCoefMatrix = np.ones((xMatrix.shape[1],), dtype=float)\n",
    "    yPredicted = xMatrix.dot(wCoefMatrix)\n",
    "    mse = []\n",
    "    for epoch in range(epochs):\n",
    "        somatorio = 0\n",
    "        for i in range(xMatrix.shape[0]):\n",
    "            somatorio += (yVector[i] - sigmoide(yPredicted[i])) * xMatrix[i]\n",
    "\n",
    "        mse.append((-1/xMatrix.shape[0]) * somatorio)\n",
    "        wCoefMatrix = wCoefMatrix + (alpha/wCoefMatrix.shape[0])*somatorio\n",
    "        yPredicted = xMatrix.dot(wCoefMatrix)\n",
    "    \n",
    "    return wCoefMatrix\n",
    "\n",
    "def stochasticGradientDescent(xMatrix, yVector, epochs, alpha):\n",
    "    xMatrix = np.insert(xMatrix, 0, 1, axis =1)\n",
    "    wCoefMatrix = np.ones((xMatrix.shape[1],), dtype=float)\n",
    "    yPredicted = xMatrix.dot(wCoefMatrix)\n",
    "    data = np.append(xMatrix, np.split(yVector, xMatrix.shape[0], axis=0), axis=1)\n",
    "    mse = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        erro = 0\n",
    "        somatorio = 0\n",
    "        for i in range(xMatrix.shape[0]):\n",
    "            wCoefMatrix  = wCoefMatrix + alpha * (yVector[i] - sigmoide(yPredicted[i])) * xMatrix[i]\n",
    "            somatorio += (yVector[i] - sigmoide(yPredicted[i])) * xMatrix[i]\n",
    "        \n",
    "        mse.append((-1/xMatrix.shape[0]) * somatorio)  \n",
    "        \n",
    "        data = np.random.permutation(data)\n",
    "        xMatrix = data[: ,0:xMatrix.shape[1]]\n",
    "        yVector = data[:,xMatrix.shape[1]]\n",
    "        \n",
    "        yPredicted = xMatrix.dot(wCoefMatrix)  \n",
    "        \n",
    "    return wCoefMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationSplit(xMatrix, yVector, n_folds): \n",
    "    xMatrixSplit = []\n",
    "    yVectorSplit = []\n",
    "    xMatrixCopy = xMatrix\n",
    "\n",
    "    yVectorCopy = yVector\n",
    "    foldSize = int(len(xMatrix) / n_folds) \n",
    "    \n",
    "    for i in range(n_folds): \n",
    "        foldXM = [] \n",
    "        foldYV = []\n",
    "        while len(foldXM) < foldSize: \n",
    "            index = rd.randrange(len(xMatrixCopy)) \n",
    "            foldXM.append(xMatrixCopy[index]) \n",
    "            xMatrixCopy = np.delete(xMatrixCopy, index, axis=0)\n",
    "            foldYV.append(yVectorCopy[index]) \n",
    "            yVectorCopy = np.delete(yVectorCopy, index)\n",
    "        xMatrixSplit.append(foldXM)\n",
    "        yVectorSplit.append(foldYV)\n",
    "    return xMatrixSplit, yVectorSplit\n",
    "\n",
    "def kFoldCrossValidation(xMatrix, yVector, kParts, algorithm, *args):\n",
    "    xMFolds, yVFolds = crossValidationSplit(xMatrix, yVector, kParts) \n",
    "    scores = list() \n",
    "    count = 0;\n",
    "    for fold in xMFolds: \n",
    "        xTrain = xMFolds\n",
    "        yTrain = yVFolds\n",
    "        \n",
    "        xTest = xTrain[count]\n",
    "        yTest = np.array(yTrain[count])\n",
    "        \n",
    "        np.delete(xTrain,count)\n",
    "        np.delete(yTrain,count)\n",
    "        \n",
    "        yTrain = np.stack(yTrain)\n",
    "        yTrain = yTrain.ravel()\n",
    "        xTrainAux = []\n",
    "\n",
    "        for i in range(kParts):\n",
    "            for j in range(len(xTrain[i])):\n",
    "                xTrainAux.append(xTrain[i][j])\n",
    "        xTrain = np.stack(xTrainAux)\n",
    "        yTest = np.where(yTest < 0, 0, yTest)\n",
    "        predicted = algorithm(xTrain, yTrain, xTest,  *args)\n",
    "        for i in range(len(predicted)):\n",
    "            print(\"Predicted: \",predicted[i],\"Actual: \",yTest[i])\n",
    "        accuracy = np.array([x - y for x, y in zip(predicted, yTest)])/kParts\n",
    "        scores.append(accuracy) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xMatrix, w):\n",
    "    predictions = []\n",
    "    xMatrix = np.insert(xMatrix, 0, 1, axis =1)\n",
    "    for i in range(xMatrix.shape[0]):\n",
    "        predictions.append(round(sigmoide(xMatrix[i].dot(w))))\n",
    "    return predictions\n",
    "\n",
    "def logisticRegression(xTrain, yTrain, xTest, alpha, epochs): \n",
    "    coef = stochasticGradientDescent(xTrain, yTrain, epochs, alpha)\n",
    "    return(predict(xTest, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000 \n",
    "alpha =  0.001\n",
    "kParts = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xMatrix, yVector = normalization(xMatrix, yVector)\n",
    "kFoldCrossValidation(xMatrix, yVector, kParts, logisticRegression, alpha, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTableMulticlass = pd.read_csv('iris_multiclasse.csv', names =['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'flower1','flower2','flower3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>flower1</th>\n",
       "      <th>flower2</th>\n",
       "      <th>flower3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  flower1  flower2  \\\n",
       "0           5.1          3.5           1.4          0.2        1        0   \n",
       "1           4.9          3.0           1.4          0.2        1        0   \n",
       "2           4.7          3.2           1.3          0.2        1        0   \n",
       "3           4.6          3.1           1.5          0.2        1        0   \n",
       "4           5.0          3.6           1.4          0.2        1        0   \n",
       "\n",
       "   flower3  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTableMulticlass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x_multiclass = np.array(dataTableMulticlass[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "vector_y_multiclass = np.array(dataTableMulticlass[['flower1', 'flower2', 'flower3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x_multiclass, vector_y_multiclass = normalization(matrix_x_multiclass, vector_y_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulticlass(matrix_x, vector_y, epochs, alpha):\n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "    \n",
    "    size = (vector_y.shape[1], matrix_x.shape[1])\n",
    "    w_matrix = np.ones(size, dtype=float)\n",
    "\n",
    "    mse = []\n",
    "    for k in range(w_matrix.shape[0]): \n",
    "        y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            somatorio = 0\n",
    "            for i in range(matrix_x.shape[0]):\n",
    "                _sum = 0\n",
    "                for j in range(w_matrix.shape[0]):\n",
    "                    _sum += np.exp(w_matrix[j].dot(matrix_x[i]))\n",
    "                \n",
    "                err = np.exp(y_aux[i])/_sum\n",
    "                somatorio += (vector_y[i][k] - err) * matrix_x[i]\n",
    "            \n",
    "            mse.append((-1/matrix_x.shape[0]) * somatorio)\n",
    "            w_matrix[k] = w_matrix[k] + (alpha/matrix_x.shape[0])*somatorio\n",
    "            y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "\n",
    "\n",
    "    return w_matrix, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_multiclass(matrix_x, vector_y, epochs, alpha):\n",
    "    \n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "    size = (vector_y.shape[1], matrix_x.shape[1])    \n",
    "    w_matrix = np.ones(size, dtype=float)\n",
    "\n",
    "    data =np.append(matrix_x, vector_y, axis=1)\n",
    "    \n",
    "    mse = []\n",
    "\n",
    "    for k in range(w_matrix.shape[0]):\n",
    "        y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(matrix_x.shape[0]):\n",
    "                _sum = 0\n",
    "                for j in range(w_matrix.shape[0]):\n",
    "                    _sum += np.exp(w_matrix[j].dot(matrix_x[i]))\n",
    "        \n",
    "                err = np.exp(y_aux[i])/_sum\n",
    "                \n",
    "                w_matrix[k] = w_matrix[k] + alpha * (vector_y[i][k] - err) * matrix_x[i]\n",
    "      \n",
    "            data = np.random.permutation(data)\n",
    "            matrix_x = data[: ,0:matrix_x.shape[1]]\n",
    "            vector_y = data[:,matrix_x.shape[1]:]\n",
    "            y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "            \n",
    "                \n",
    "    return w_matrix, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationSplitMulticlass(xMatrix, yVector, n_folds): \n",
    "    xMatrixSplit = []\n",
    "    yVectorSplit = []\n",
    "    xMatrixCopy = xMatrix\n",
    "\n",
    "    yVectorCopy = yVector\n",
    "\n",
    "    foldSize = int(len(xMatrix) / n_folds) \n",
    "    \n",
    "    for i in range(n_folds): \n",
    "        foldXM = [] \n",
    "        foldYV = []\n",
    "        while len(foldXM) < foldSize: \n",
    "            index = rd.randrange(len(xMatrixCopy)) \n",
    "            foldXM.append(xMatrixCopy[index]) \n",
    "            xMatrixCopy = np.delete(xMatrixCopy, index, axis=0)\n",
    "            foldYV.append(yVectorCopy[index]) \n",
    "            yVectorCopy = np.delete(yVectorCopy, index,axis=0)\n",
    "        xMatrixSplit.append(foldXM)\n",
    "        yVectorSplit.append(foldYV)\n",
    "\n",
    "    return xMatrixSplit, yVectorSplit\n",
    "\n",
    "def kFoldCrossValidationMulticlass(xMatrix, yVector, kParts, algorithm, *args):\n",
    "    xMFolds, yVFolds = crossValidationSplitMulticlass(xMatrix, yVector, kParts) \n",
    "    scores = list() \n",
    "    count = 0;\n",
    "    for fold in xMFolds: \n",
    "        xTrain = xMFolds\n",
    "        yTrain = yVFolds\n",
    "        \n",
    "        xTest = xTrain[count]\n",
    "        yTest = np.array(yTrain[count])\n",
    "        \n",
    "        np.delete(xTrain,count)\n",
    "        np.delete(yTrain,count)\n",
    "        \n",
    "        xTrainAux = []\n",
    "        yTrainAux = []\n",
    "        for i in range(kParts):\n",
    "            for j in range(len(yTrain[i])):\n",
    "                yTrainAux.append(yTrain[i][j])\n",
    "        for i in range(kParts):\n",
    "            for j in range(len(xTrain[i])):\n",
    "                xTrainAux.append(xTrain[i][j])\n",
    "        xTrain = np.stack(xTrainAux)\n",
    "        yTrain = np.stack(yTrainAux)\n",
    "        \n",
    "        predicted = algorithm(xTrain, yTrain, xTest,  *args)\n",
    "        for i in range(len(predicted)):\n",
    "            aux = np.array([round(x) for x in yTest[i]])\n",
    "            aux = np.where(aux < 0, 0, aux)\n",
    "            print(\"Predicted: \",predicted[i],\"Actual: \", aux)\n",
    "        accuracy = np.array([x - y for x, y in zip(predicted, aux)])/kParts\n",
    "        scores.append(accuracy) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiclass_logistic_regression(matrix_x_multiclass, w):\n",
    "    \n",
    "    matrix_x_multiclass = np.insert(matrix_x_multiclass, 0, 1, axis =1)\n",
    "    size = (matrix_x_multiclass.shape[0], w.shape[0])\n",
    "    predictions = np.ones(size, dtype=float)\n",
    "    \n",
    "    for k in range(w.shape[0]):   \n",
    "        for i in range(matrix_x_multiclass.shape[0]):\n",
    "            num = np.exp(w[k].dot(matrix_x_multiclass[i]))\n",
    "            sum_ = 0\n",
    "            for j in range(w.shape[0]):\n",
    "                sum_ = sum_ + np.exp(w[j].dot(matrix_x_multiclass[i]))\n",
    "            predictions[i][k] = num/sum_\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        index = np.argmax(predictions[i], axis=0)\n",
    "        for j in range(len(predictions[i])):\n",
    "            if(j == index):\n",
    "                predictions[i][index] = 1.0\n",
    "            else:\n",
    "                predictions[i][j] = 0.0\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegressionMulticlass(xTrain, yTrain, xTest, alpha, epochs): \n",
    "    #xTrain, yTrain = normalization(xTrain, yTrain)\n",
    "    coef, mse = stochastic_gradient_descent_multiclass(xTrain, yTrain, epochs, alpha)\n",
    "    return(predict_multiclass_logistic_regression(xTest, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.2,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. , -0.2, -0.2]]), array([[ 0.2,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. , -0.2, -0.2]]), array([[ 0.2,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. , -0.2, -0.2]]), array([[ 0.2,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. , -0.2, -0.2]]), array([[ 0.2,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. , -0.2, -0.2]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kFoldCrossValidationMulticlass(matrix_x_multiclass, vector_y_multiclass, kParts, logisticRegressionMulticlass, alpha, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
